{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a29031c",
   "metadata": {},
   "source": [
    "The F1 score is a statistical measure used to evaluate the performance of a binary classification model, especially in situations where the classes are imbalanced. It is the harmonic mean of precision and recall, providing a balance between these two metrics.\n",
    "\n",
    "Calculation of the F1 Score\n",
    "The F1 score is calculated using the precision and recall of the model. These are defined as:\n",
    "\n",
    "Precision: The ratio of true positive predictions to the total number of positive predictions (i.e., the sum of true positives and false positives).\n",
    "Precision\n",
    "=\n",
    "True Positives (TP)\n",
    "TP\n",
    "+\n",
    "False Positives (FP)\n",
    "Precision= \n",
    "TP+False Positives (FP)\n",
    "True Positives (TP)\n",
    "​\n",
    " \n",
    "\n",
    "Recall: The ratio of true positive predictions to the total number of actual positive instances (i.e., the sum of true positives and false negatives).\n",
    "Recall\n",
    "=\n",
    "TP\n",
    "TP\n",
    "+\n",
    "False Negatives (FN)\n",
    "Recall= \n",
    "TP+False Negatives (FN)\n",
    "TP\n",
    "​\n",
    " \n",
    "\n",
    "The F1 score is then calculated as:\n",
    "F1 Score\n",
    "=\n",
    "2\n",
    "×\n",
    "Precision\n",
    "×\n",
    "Recall\n",
    "Precision\n",
    "+\n",
    "Recall\n",
    "F1 Score=2× \n",
    "Precision+Recall\n",
    "Precision×Recall\n",
    "​\n",
    " \n",
    "\n",
    "Understanding the F1 Score\n",
    "The F1 score ranges from 0 to 1, where 1 is the best possible score (perfect precision and recall), and 0 is the worst.\n",
    "It is a harmonic mean, which means it gives more weight to lower values. As a result, the classifier will only achieve a high F1 score if both recall and precision are high.\n",
    "The F1 score is particularly useful when the costs of false positives and false negatives are roughly equivalent, and when the classes are imbalanced.\n",
    "Difference from Precision and Recall\n",
    "Precision focuses on the proportion of true positive predictions among all positive predictions made. It does not take into account the false negatives.\n",
    "Recall focuses on the proportion of true positive predictions among all actual positives. It does not consider the false positives.\n",
    "F1 Score balances precision and recall. It is a single metric that encapsulates both the false positives (as considered by precision) and the false negatives (as considered by recall)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
