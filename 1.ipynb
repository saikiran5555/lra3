{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9e4458",
   "metadata": {},
   "source": [
    "Precision and recall are two fundamental metrics used to evaluate the performance of classification models, especially in scenarios where classes are imbalanced. They provide insight into the model's accuracy in predicting each class. Here’s an overview:\n",
    "\n",
    "Precision\n",
    "Definition: Precision measures the accuracy of the positive predictions made by the model. It's the proportion of positive identifications that were actually correct.\n",
    "Formula: \n",
    "Precision\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "Precision= \n",
    "TP+FP\n",
    "TP\n",
    "​\n",
    " \n",
    "Interpretation: A high precision means that the model makes very few false positive errors. In other words, when the model predicts a positive class, it is likely to be correct.\n",
    "Use Case: Precision is particularly important in scenarios where false positives are more costly than false negatives. For instance, in email spam detection, a high precision model would not incorrectly classify important emails as spam.\n",
    "Recall (Sensitivity or True Positive Rate)\n",
    "Definition: Recall measures the model's ability to correctly identify all actual positives. It's the proportion of actual positives that were identified correctly.\n",
    "Formula: \n",
    "Recall\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "Recall= \n",
    "TP+FN\n",
    "TP\n",
    "​\n",
    " \n",
    "Interpretation: A high recall means that the model is good at detecting the positive class. However, a model with high recall might also have a high number of false positives.\n",
    "Use Case: Recall is crucial in situations where missing a positive is more critical than falsely labeling a negative as a positive. For example, in medical diagnostics for a life-threatening disease, high recall would mean most patients with the disease are correctly identified.\n",
    "Balancing Precision and Recall\n",
    "Often, there is a trade-off between precision and recall. Improving precision typically reduces recall and vice versa. This trade-off is crucial in scenarios where both false positives and false negatives carry significant costs.\n",
    "The F1 score is a metric that combines precision and recall into a single number by taking their harmonic mean, helping to balance these two metrics.\n",
    "Example\n",
    "Consider a medical test for a disease:\n",
    "\n",
    "If the test has high precision but low recall, it means that most of the patients it identifies as having the disease actually do have the disease, but it misses a lot of patients who do have the disease.\n",
    "Conversely, if the test has high recall but low precision, it identifies most of the patients with the disease, but it also incorrectly identifies many healthy patients as having the disease."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
