{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0f915a",
   "metadata": {},
   "source": [
    "ROC (Receiver Operating Characteristic) and AUC (Area Under the Curve) are statistical measures used to evaluate the performance of classification models, especially binary classification models. They are particularly useful for assessing the model's ability to distinguish between two classes under various threshold settings.\n",
    "\n",
    "ROC Curve\n",
    "Definition: The ROC curve is a graphical representation that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.\n",
    "Components:\n",
    "The x-axis represents the False Positive Rate (FPR, 1 - Specificity): \n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "FPR= \n",
    "TN+FP\n",
    "FP\n",
    "​\n",
    " \n",
    "The y-axis represents the True Positive Rate (TPR, Recall or Sensitivity): \n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "TPR= \n",
    "TP+FN\n",
    "TP\n",
    "​\n",
    " \n",
    "Plotting: The ROC curve plots TPR against FPR at various threshold settings. Starting at the bottom left (representing a model that predicts all instances as negative) to the top right (all instances as positive).\n",
    "Interpretation: A model with perfect discrimination (no overlap between the two distributions of the classes) has an ROC curve passing through the top left corner (100% sensitivity, 100% specificity). Therefore, the closer the ROC curve is to the top left corner, the higher the overall accuracy of the test.\n",
    "AUC\n",
    "Definition: The AUC, or Area Under the ROC Curve, quantifies the overall ability of the model to discriminate between positive and negative classes.\n",
    "Interpretation:\n",
    "An AUC of 1 indicates a perfect model; all positive cases rank higher than all negative cases.\n",
    "0.5 suggests no discriminative ability (equivalent to random guessing).\n",
    "Below 0.5 means worse than random guessing, indicating a problem with the model.\n",
    "Advantages: AUC is scale-invariant (it measures how well predictions are ranked rather than their absolute values) and classification-threshold-invariant (it measures the quality of the model's predictions irrespective of what classification threshold is used).\n",
    "Using ROC and AUC\n",
    "Model Selection: By comparing the ROC curves and AUC scores of different models, you can choose the model that best discriminates between the two classes.\n",
    "Performance Evaluation: These metrics provide a more nuanced view of model performance than simply considering accuracy, especially in imbalanced datasets.\n",
    "Example\n",
    "In a medical diagnosis problem for a rare disease (imbalanced dataset):\n",
    "\n",
    "A model might achieve high accuracy by predicting 'no disease' for all patients, but this would be misleading.\n",
    "ROC and AUC would reveal this issue since they take into account both the false positive rate and the true positive rate, providing a more balanced view of the model's ability to distinguish between the two classes (disease vs. no disease)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
