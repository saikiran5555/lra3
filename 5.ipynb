{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b092fd",
   "metadata": {},
   "source": [
    "Logistic regression is primarily used for binary classification tasks, but it can be extended to handle multiclass classification problems. This is typically achieved through techniques like One-vs-Rest (OvR) or One-vs-One (OvO).\n",
    "\n",
    "One-vs-Rest (OvR) Method\n",
    "Concept: In OvR, also known as One-vs-All, a separate logistic regression classifier is trained for each class to distinguish that class from all other classes.\n",
    "Implementation: For a problem with \n",
    "�\n",
    "N classes, \n",
    "�\n",
    "N different logistic regression models are trained. Each model predicts the probability that a given instance belongs to its 'one' class versus any of the 'rest'.\n",
    "Prediction: For a new instance, each of the \n",
    "�\n",
    "N classifiers gives a probability score for its class. The class corresponding to the classifier with the highest score is the final prediction.\n",
    "Example: In a classification task with three classes (A, B, C), three logistic regression models are built:\n",
    "Model 1: Class A vs. Classes B and C\n",
    "Model 2: Class B vs. Classes A and C\n",
    "Model 3: Class C vs. Classes A and B\n",
    "One-vs-One (OvO) Method\n",
    "Concept: OvO involves training a logistic regression model for every pair of classes.\n",
    "Implementation: For \n",
    "�\n",
    "N classes, \n",
    "�\n",
    "(\n",
    "�\n",
    "−\n",
    "1\n",
    ")\n",
    "/\n",
    "2\n",
    "N(N−1)/2 models are trained. Each model is trained on data from two classes and learns to distinguish these two classes.\n",
    "Prediction: For a new instance, it is run through all models, and the class that wins the most duels (is chosen by the most classifiers) is the final prediction.\n",
    "Example: In a classification task with three classes (A, B, C), three logistic regression models are built:\n",
    "Model 1: Class A vs. Class B\n",
    "Model 2: Class A vs. Class C\n",
    "Model 3: Class B vs. Class C\n",
    "Considerations\n",
    "Scalability: OvR is generally preferred because it involves training fewer models compared to OvO. OvO can be computationally expensive as the number of classes increases.\n",
    "Imbalance: OvR can be more susceptible to class imbalance in the training data.\n",
    "Decision Boundaries: OvO might be more effective when the decision boundaries between classes are not linear.\n",
    "Example in Real-World Scenario\n",
    "Consider a handwriting recognition problem where the task is to classify digits (0 to 9). Using the OvR approach, you would train 10 logistic regression models, each designed to recognize one digit against all others. For example, one model might be trained to distinguish '0' from all other digits (1-9), another to distinguish '1', and so on. When classifying a new digit, the model that gives the highest probability score for its respective class determines the predicted digit.\n",
    "\n",
    "In conclusion, logistic regression can be effectively adapted for multiclass classification problems using strategies like One-vs-Rest or One-vs-One, depending on the specific requirements and characteristics of the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
